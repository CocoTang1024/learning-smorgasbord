{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplication complete. Output written to ../data/20250508_scopus_3837_tad_tal 20250508_wos_886_tad_tal_deduplication.ris\n",
      "Log written to deduplication_log_*.txt\n"
     ]
    }
   ],
   "source": [
    "# 3.处理重复的条目，保留最详细的，并且在日志里面输出当前去重过的期刊\n",
    "import uuid\n",
    "import logging\n",
    "import datetime\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def normalize_title(title):\n",
    "    \"\"\"Normalize title for comparison by removing case and punctuation.\"\"\"\n",
    "    return re.sub(r'[^\\w\\s]', '', title.lower()).strip()\n",
    "\n",
    "def parse_ris_file(file_path):\n",
    "    \"\"\"Parse RIS file and return a list of entries.\"\"\"\n",
    "    entries = []\n",
    "    current_entry = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line == 'ER  -':\n",
    "                if current_entry:\n",
    "                    entries.append(current_entry)\n",
    "                    current_entry = {}\n",
    "            elif line:\n",
    "                tag, value = line.split('  - ', 1) if '  - ' in line else (line, '')\n",
    "                current_entry[tag] = current_entry.get(tag, []) + [value]\n",
    "    return entries\n",
    "\n",
    "def count_entry_fields(entry):\n",
    "    \"\"\"Count the number of fields (data lines) in an entry.\"\"\"\n",
    "    return sum(len(values) for values in entry.values())\n",
    "\n",
    "def deduplicate_by_field(entries, field, normalize=False):\n",
    "    \"\"\"Deduplicate entries based on a specified field, keeping the one with most fields.\"\"\"\n",
    "    field_to_entries = defaultdict(list)\n",
    "    for entry in entries:\n",
    "        field_value = entry.get(field, [''])[0]\n",
    "        if field_value:  # Only process entries with the field\n",
    "            key = normalize_title(field_value) if normalize else field_value\n",
    "            field_to_entries[key].append(entry)\n",
    "    \n",
    "    deduplicated = []\n",
    "    log_messages = []\n",
    "    \n",
    "    for key, entries_group in field_to_entries.items():\n",
    "        if len(entries_group) > 1:\n",
    "            # Sort by number of fields (descending) and keep the one with most fields\n",
    "            entries_group.sort(key=count_entry_fields, reverse=True)\n",
    "            kept_entry = entries_group[0]\n",
    "            deduplicated.append(kept_entry)\n",
    "            # Log removed entries\n",
    "            for removed_entry in entries_group[1:]:\n",
    "                log_messages.append(\n",
    "                    f\"Removed duplicate entry with {field} '{key}' \"\n",
    "                    f\"(kept {count_entry_fields(kept_entry)} fields, \"\n",
    "                    f\"removed {count_entry_fields(removed_entry)} fields, \"\n",
    "                    f\"title: '{removed_entry.get('TI', [''])[0]}')\"\n",
    "                )\n",
    "        else:\n",
    "            deduplicated.append(entries_group[0])\n",
    "    \n",
    "    # Add entries that didn't have the field\n",
    "    for entry in entries:\n",
    "        if not entry.get(field, [''])[0]:\n",
    "            deduplicated.append(entry)\n",
    "    \n",
    "    return deduplicated, log_messages\n",
    "\n",
    "def deduplicate_entries(entries):\n",
    "    \"\"\"Deduplicate entries first by TI, then by DO.\"\"\"\n",
    "    # Step 1: Deduplicate by TI\n",
    "    entries, ti_log_messages = deduplicate_by_field(entries, 'TI', normalize=True)\n",
    "    \n",
    "    # Step 2: Deduplicate by DO\n",
    "    entries, do_log_messages = deduplicate_by_field(entries, 'DO', normalize=False)\n",
    "    \n",
    "    return entries, ti_log_messages + do_log_messages\n",
    "\n",
    "def write_ris_file(entries, output_path):\n",
    "    \"\"\"Write deduplicated entries to a new RIS file with a blank line between entries.\"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as file:\n",
    "        for i, entry in enumerate(entries):\n",
    "            for tag, values in entry.items():\n",
    "                for value in values:\n",
    "                    file.write(f\"{tag}  - {value}\\n\")\n",
    "            file.write(\"ER  -\\n\")\n",
    "            if i < len(entries) - 1:  # Add blank line between entries, but not after the last\n",
    "                file.write(\"\\n\")\n",
    "\n",
    "def setup_logging():\n",
    "    \"\"\"Set up logging to a file.\"\"\"\n",
    "    logging.basicConfig(\n",
    "        filename=f'deduplication_log_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.txt',\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(message)s'\n",
    "    )\n",
    "\n",
    "def main(input_file, output_file):\n",
    "    setup_logging()\n",
    "    \n",
    "    # Parse RIS file\n",
    "    entries = parse_ris_file(input_file)\n",
    "    \n",
    "    # Deduplicate entries\n",
    "    deduplicated_entries, log_messages = deduplicate_entries(entries)\n",
    "    \n",
    "    # Write to output file\n",
    "    write_ris_file(deduplicated_entries, output_file)\n",
    "    \n",
    "    # Log results\n",
    "    for message in log_messages:\n",
    "        logging.info(message)\n",
    "    \n",
    "    logging.info(f\"Processed {len(entries)} entries, kept {len(deduplicated_entries)} entries\")\n",
    "    print(f\"Deduplication complete. Output written to {output_file}\")\n",
    "    print(f\"Log written to deduplication_log_*.txt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"../data/20250508_scopus_3837_tad_tal 20250508_wos_886_tad_tal.ris\"  # Replace with your input RIS file path\n",
    "    output_file = \"../data/20250508_scopus_3837_tad_tal 20250508_wos_886_tad_tal_deduplication.ris\"  # Replace with your desired output RIS file path\n",
    "    main(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplication complete. Output written to ../data/20250508_scopus_3837_tad_tal 20250508_wos_886_tad_tal_deduplication.ris\n",
      "Log written to deduplication_log_*.txt\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import logging\n",
    "import datetime\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def normalize_title(title):\n",
    "    \"\"\"Normalize title for comparison by removing case, punctuation, and handling hyphens.\"\"\"\n",
    "    # Replace hyphens with spaces and remove multiple hyphens\n",
    "    title = re.sub(r'-+', ' ', title)\n",
    "    # Remove all punctuation and normalize to lowercase\n",
    "    title = re.sub(r'[^\\w\\s]', '', title.lower()).strip()\n",
    "    # Remove extra spaces\n",
    "    title = re.sub(r'\\s+', ' ', title)\n",
    "    return title\n",
    "\n",
    "def parse_ris_file(file_path):\n",
    "    \"\"\"Parse RIS file and return a list of entries.\"\"\"\n",
    "    entries = []\n",
    "    current_entry = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line == 'ER  -':\n",
    "                if current_entry:\n",
    "                    entries.append(current_entry)\n",
    "                    current_entry = {}\n",
    "            elif line:\n",
    "                tag, value = line.split('  - ', 1) if '  - ' in line else (line, '')\n",
    "                current_entry[tag] = current_entry.get(tag, []) + [value]\n",
    "    return entries\n",
    "\n",
    "def count_entry_fields(entry):\n",
    "    \"\"\"Count the number of fields (data lines) in an entry.\"\"\"\n",
    "    return sum(len(values) for values in entry.values())\n",
    "\n",
    "def deduplicate_by_field(entries, field, normalize=False):\n",
    "    \"\"\"Deduplicate entries based on a specified field, keeping the one with most fields.\"\"\"\n",
    "    field_to_entries = defaultdict(list)\n",
    "    for entry in entries:\n",
    "        field_value = entry.get(field, [''])[0]\n",
    "        if field_value:  # Only process entries with the field\n",
    "            key = normalize_title(field_value) if normalize else field_value\n",
    "            field_to_entries[key].append(entry)\n",
    "    \n",
    "    deduplicated = []\n",
    "    log_messages = []\n",
    "    \n",
    "    for key, entries_group in field_to_entries.items():\n",
    "        if len(entries_group) > 1:\n",
    "            # Sort by number of fields (descending) and keep the one with most fields\n",
    "            entries_group.sort(key=count_entry_fields, reverse=True)\n",
    "            kept_entry = entries_group[0]\n",
    "            deduplicated.append(kept_entry)\n",
    "            # Log removed entries\n",
    "            for removed_entry in entries_group[1:]:\n",
    "                log_messages.append(\n",
    "                    f\"Removed duplicate entry with {field} '{key}' \"\n",
    "                    f\"(kept {count_entry_fields(kept_entry)} fields, \"\n",
    "                    f\"removed {count_entry_fields(removed_entry)} fields, \"\n",
    "                    f\"title: '{removed_entry.get('TI', [''])[0]}')\"\n",
    "                )\n",
    "        else:\n",
    "            deduplicated.append(entries_group[0])\n",
    "    \n",
    "    # Add entries that didn't have the field\n",
    "    for entry in entries:\n",
    "        if not entry.get(field, [''])[0]:\n",
    "            deduplicated.append(entry)\n",
    "    \n",
    "    return deduplicated, log_messages\n",
    "\n",
    "def deduplicate_entries(entries):\n",
    "    \"\"\"Deduplicate entries first by TI, then by DO.\"\"\"\n",
    "    # Step 1: Deduplicate by TI\n",
    "    entries, ti_log_messages = deduplicate_by_field(entries, 'TI', normalize=True)\n",
    "    \n",
    "    # Step 2: Deduplicate by DO\n",
    "    entries, do_log_messages = deduplicate_by_field(entries, 'DO', normalize=False)\n",
    "    \n",
    "    return entries, ti_log_messages + do_log_messages\n",
    "\n",
    "def write_ris_file(entries, output_path):\n",
    "    \"\"\"Write deduplicated entries to a new RIS file with a blank line between entries.\"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as file:\n",
    "        for i, entry in enumerate(entries):\n",
    "            for tag, values in entry.items():\n",
    "                for value in values:\n",
    "                    file.write(f\"{tag}  - {value}\\n\")\n",
    "            file.write(\"ER  -\\n\")\n",
    "            if i < len(entries) - 1:  # Add blank line between entries, but not after the last\n",
    "                file.write(\"\\n\")\n",
    "\n",
    "def setup_logging():\n",
    "    \"\"\"Set up logging to a file.\"\"\"\n",
    "    logging.basicConfig(\n",
    "        filename=f'deduplication_log_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.txt',\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(message)s'\n",
    "    )\n",
    "\n",
    "def main(input_file, output_file):\n",
    "    setup_logging()\n",
    "    \n",
    "    # Parse RIS file\n",
    "    entries = parse_ris_file(input_file)\n",
    "    \n",
    "    # Deduplicate entries\n",
    "    deduplicated_entries, log_messages = deduplicate_entries(entries)\n",
    "    \n",
    "    # Write to output file\n",
    "    write_ris_file(deduplicated_entries, output_file)\n",
    "    \n",
    "    # Log results\n",
    "    for message in log_messages:\n",
    "        logging.info(message)\n",
    "    \n",
    "    logging.info(f\"Processed {len(entries)} entries, kept {len(deduplicated_entries)} entries\")\n",
    "    print(f\"Deduplication complete. Output written to {output_file}\")\n",
    "    print(f\"Log written to deduplication_log_*.txt\")\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"../data/20250508_scopus_3837_tad_tal 20250508_wos_886_tad_tal.ris\"  # Replace with your input RIS file path\n",
    "    output_file = \"../data/20250508_scopus_3837_tad_tal 20250508_wos_886_tad_tal_deduplication.ris\"  # Replace with your desired output RIS file path\n",
    "    main(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Entries Report\n",
      "==============================\n",
      "\n",
      "Found 2 entries in file2 that are not in file1:\n",
      "--------------------------------------------------\n",
      "Entry 1:\n",
      "  Title: Weakly-Supervised Temporal Action Localization Through Local-Global Background Modeling\n",
      "  Authors: Huang, Z., Qing, Z., Sang, N., Shao, Y., Wang, X.\n",
      "  DOI: 10.48550/arXiv.2106.11811\n",
      "  Journal: CVPR-2021 HACS Challenge - Weakly-supervised Learning Track champion solution (1st Place)\n",
      "\n",
      "Entry 2:\n",
      "  Title: Learning Spatio-Temporal Representation With Local and Global Diffusion\n",
      "  Authors: Mei, T., Ngox, C.-W., Qiuy, Z., Tiany, X., Yaoz, T.\n",
      "  DOI: 10.1109/cvpr.2019.01233\n",
      "  Journal: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\n",
      "\n",
      "\n",
      "Report saved to missing_entries_report_348ae166-ba6a-46a6-ba8c-40c1ca093118.txt\n"
     ]
    }
   ],
   "source": [
    "# 找不同\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import uuid\n",
    "\n",
    "def parse_ris_entries(file_path):\n",
    "    \"\"\"Parse a RIS file and return a list of dictionaries, each representing an entry.\"\"\"\n",
    "    entries = []\n",
    "    current_entry = defaultdict(list)\n",
    "    current_tag = None\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                \n",
    "                # Match RIS tag format (e.g., \"TY  - JOUR\")\n",
    "                match = re.match(r'^([A-Z0-9]{2})\\s*-\\s*(.*)$', line)\n",
    "                if match:\n",
    "                    tag, value = match.groups()\n",
    "                    if tag == 'ER':\n",
    "                        # End of entry, save it\n",
    "                        if current_entry:\n",
    "                            # Convert lists to single values where appropriate\n",
    "                            for key in current_entry:\n",
    "                                if len(current_entry[key]) == 1:\n",
    "                                    current_entry[key] = current_entry[key][0]\n",
    "                                elif key == 'AU' or key == 'KW':\n",
    "                                    current_entry[key] = sorted(current_entry[key])\n",
    "                            entries.append(dict(current_entry))\n",
    "                            current_entry = defaultdict(list)\n",
    "                        continue\n",
    "                    if tag == 'TY' and current_entry:\n",
    "                        # New entry starts, save previous\n",
    "                        for key in current_entry:\n",
    "                            if len(current_entry[key]) == 1:\n",
    "                                current_entry[key] = current_entry[key][0]\n",
    "                            elif key == 'AU' or key == 'KW':\n",
    "                                current_entry[key] = sorted(current_entry[key])\n",
    "                        entries.append(dict(current_entry))\n",
    "                        current_entry = defaultdict(list)\n",
    "                    current_tag = tag\n",
    "                    current_entry[current_tag].append(value.strip())\n",
    "                elif current_tag and line:\n",
    "                    # Continuation of multi-line field\n",
    "                    current_entry[current_tag][-1] += ' ' + line.strip()\n",
    "    \n",
    "        # Save the last entry if exists\n",
    "        if current_entry:\n",
    "            for key in current_entry:\n",
    "                if len(current_entry[key]) == 1:\n",
    "                    current_entry[key] = current_entry[key][0]\n",
    "                elif key == 'AU' or key == 'KW':\n",
    "                    current_entry[key] = sorted(current_entry[key])\n",
    "            entries.append(dict(current_entry))\n",
    "    \n",
    "        return entries\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {file_path} not found.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {file_path}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def find_missing_entries(file1_path, file2_path):\n",
    "    \"\"\"Find entries in file2 that are not in file1, based on title (TI).\"\"\"\n",
    "    entries1 = parse_ris_entries(file1_path)  # 3882 entries\n",
    "    entries2 = parse_ris_entries(file2_path)  # 3891 entries\n",
    "    \n",
    "    if not entries1 or not entries2:\n",
    "        return {\"error\": \"One or both files could not be parsed.\"}\n",
    "    \n",
    "    # Create sets of titles for comparison\n",
    "    titles1 = {entry.get('TI', '') for entry in entries1 if entry.get('TI')}\n",
    "    titles2 = {entry.get('TI', '') for entry in entries2 if entry.get('TI')}\n",
    "    \n",
    "    # Find titles in file2 but not in file1\n",
    "    missing_titles = titles2 - titles1\n",
    "    \n",
    "    # Collect full entries for missing titles\n",
    "    missing_entries = [entry for entry in entries2 if entry.get('TI') in missing_titles]\n",
    "    \n",
    "    return missing_entries\n",
    "\n",
    "def generate_report(missing_entries):\n",
    "    \"\"\"Generate a report listing the missing entries.\"\"\"\n",
    "    report = [\"Missing Entries Report\", \"=\" * 30, \"\"]\n",
    "    \n",
    "    if isinstance(missing_entries, dict) and 'error' in missing_entries:\n",
    "        report.append(f\"Error: {missing_entries['error']}\")\n",
    "        return '\\n'.join(report)\n",
    "    \n",
    "    report.append(f\"Found {len(missing_entries)} entries in file2 that are not in file1:\")\n",
    "    report.append(\"-\" * 50)\n",
    "    \n",
    "    for i, entry in enumerate(missing_entries, 1):\n",
    "        title = entry.get('TI', 'No title')\n",
    "        authors = entry.get('AU', 'No authors')\n",
    "        doi = entry.get('DO', 'No DOI')\n",
    "        journal = entry.get('T2', 'No journal')\n",
    "        \n",
    "        report.append(f\"Entry {i}:\")\n",
    "        report.append(f\"  Title: {title}\")\n",
    "        report.append(f\"  Authors: {', '.join(authors) if isinstance(authors, list) else authors}\")\n",
    "        report.append(f\"  DOI: {doi}\")\n",
    "        report.append(f\"  Journal: {journal}\")\n",
    "        report.append(\"\")\n",
    "    \n",
    "    return '\\n'.join(report)\n",
    "\n",
    "def main():\n",
    "    # File paths\n",
    "    file1_path = R'../data/20250508_scopus_3837_tad_tal 20250508_wos_886_tad_tal_3891-3_3888_deduplication_end_arxiv_1635_5523_deduplication_4374.ris'  # Smaller file\n",
    "    file2_path = R'../data/4373.ris'  # Larger file\n",
    "    \n",
    "    missing_entries = find_missing_entries(file1_path, file2_path)\n",
    "    report = generate_report(missing_entries)\n",
    "    \n",
    "    # Print report to console\n",
    "    print(report)\n",
    "    \n",
    "    # Save report to file\n",
    "    report_file = f'missing_entries_report_{uuid.uuid4()}.txt'\n",
    "    with open(report_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(report)\n",
    "    print(f\"\\nReport saved to {report_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplication complete. Output written to ../data/20250510_scopus_LNCS_tad_tal_303_processed.ris\n",
      "Log written to deduplication_log_*.txt\n"
     ]
    }
   ],
   "source": [
    "# 找到ris文件之间的区别\n",
    "import uuid\n",
    "import logging\n",
    "import datetime\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def normalize_title(title):\n",
    "    \"\"\"Normalize title for comparison by handling hyphens only.\"\"\"\n",
    "    # Replace single or multiple hyphens with a single space\n",
    "    title = re.sub(r'-+', ' ', title)\n",
    "    # Remove extra spaces\n",
    "    title = re.sub(r'\\s+', ' ', title).strip()\n",
    "    return title\n",
    "\n",
    "def parse_ris_file(file_path):\n",
    "    \"\"\"Parse RIS file and return a list of entries.\"\"\"\n",
    "    entries = []\n",
    "    current_entry = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line == 'ER  -':\n",
    "                if current_entry:\n",
    "                    entries.append(current_entry)\n",
    "                    current_entry = {}\n",
    "            elif line:\n",
    "                tag, value = line.split('  - ', 1) if '  - ' in line else (line, '')\n",
    "                current_entry[tag] = current_entry.get(tag, []) + [value]\n",
    "    return entries\n",
    "\n",
    "def count_entry_fields(entry):\n",
    "    \"\"\"Count the number of fields (data lines) in an entry.\"\"\"\n",
    "    return sum(len(values) for values in entry.values())\n",
    "\n",
    "def deduplicate_by_field(entries, field, normalize=False):\n",
    "    \"\"\"Deduplicate entries based on a specified field, keeping the one with most fields.\"\"\"\n",
    "    field_to_entries = defaultdict(list)\n",
    "    for entry in entries:\n",
    "        field_value = entry.get(field, [''])[0]\n",
    "        if field_value:  # Only process entries with the field\n",
    "            key = normalize_title(field_value) if normalize else field_value\n",
    "            field_to_entries[key].append(entry)\n",
    "    \n",
    "    deduplicated = []\n",
    "    log_messages = []\n",
    "    \n",
    "    for key, entries_group in field_to_entries.items():\n",
    "        if len(entries_group) > 1:\n",
    "            # Sort by number of fields (descending) and keep the one with most fields\n",
    "            entries_group.sort(key=count_entry_fields, reverse=True)\n",
    "            kept_entry = entries_group[0]\n",
    "            deduplicated.append(kept_entry)\n",
    "            # Log removed entries\n",
    "            for removed_entry in entries_group[1:]:\n",
    "                log_messages.append(\n",
    "                    f\"Removed duplicate entry with {field} '{key}' \"\n",
    "                    f\"(kept {count_entry_fields(kept_entry)} fields, \"\n",
    "                    f\"removed {count_entry_fields(removed_entry)} fields, \"\n",
    "                    f\"title: '{removed_entry.get('TI', [''])[0]}')\"\n",
    "                )\n",
    "        else:\n",
    "            deduplicated.append(entries_group[0])\n",
    "    \n",
    "    # Add entries that didn't have the field\n",
    "    for entry in entries:\n",
    "        if not entry.get(field, [''])[0]:\n",
    "            deduplicated.append(entry)\n",
    "    \n",
    "    return deduplicated, log_messages\n",
    "\n",
    "def deduplicate_entries(entries):\n",
    "    \"\"\"Deduplicate entries first by TI, then by DO.\"\"\"\n",
    "    # Step 1: Deduplicate by TI\n",
    "    entries, ti_log_messages = deduplicate_by_field(entries, 'TI', normalize=True)\n",
    "    \n",
    "    # Step 2: Deduplicate by DO\n",
    "    entries, do_log_messages = deduplicate_by_field(entries, 'DO', normalize=False)\n",
    "    \n",
    "    return entries, ti_log_messages + do_log_messages\n",
    "\n",
    "def write_ris_file(entries, output_path):\n",
    "    \"\"\"Write deduplicated entries to a new RIS file with a blank line between entries.\"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as file:\n",
    "        for i, entry in enumerate(entries):\n",
    "            for tag, values in entry.items():\n",
    "                for value in values:\n",
    "                    file.write(f\"{tag}  - {value}\\n\")\n",
    "            file.write(\"ER  -\\n\")\n",
    "            if i < len(entries) - 1:  # Add blank line between entries, but not after the last\n",
    "                file.write(\"\\n\")\n",
    "\n",
    "def setup_logging():\n",
    "    \"\"\"Set up logging to a file.\"\"\"\n",
    "    logging.basicConfig(\n",
    "        filename=f'deduplication_log_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.txt',\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(message)s'\n",
    "    )\n",
    "\n",
    "def main(input_file, output_file):\n",
    "    setup_logging()\n",
    "    \n",
    "    # Parse RIS file\n",
    "    entries = parse_ris_file(input_file)\n",
    "    \n",
    "    # Deduplicate entries\n",
    "    deduplicated_entries, log_messages = deduplicate_entries(entries)\n",
    "    \n",
    "    # Write to output file\n",
    "    write_ris_file(deduplicated_entries, output_file)\n",
    "    \n",
    "    # Log results\n",
    "    for message in log_messages:\n",
    "        logging.info(message)\n",
    "    \n",
    "    logging.info(f\"Processed {len(entries)} entries, kept {len(deduplicated_entries)} entries\")\n",
    "    print(f\"Deduplication complete. Output written to {output_file}\")\n",
    "    print(f\"Log written to deduplication_log_*.txt\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    input_file = '../data/20250510_scopus_LNCS_tad_tal_303.ris'\n",
    "    output_file = '../data/20250510_scopus_LNCS_tad_tal_303_processed.ris'\n",
    "    main(input_file, output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import List, Set\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import os\n",
    "\n",
    "def parse_ris_file(file_path: str) -> List[str]:\n",
    "    \"\"\"Parse RIS file and extract TI (title) entries.\"\"\"\n",
    "    titles = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            # Split into individual references by 'ER  -' delimiter\n",
    "            references = content.split('ER  -')\n",
    "            for ref in references:\n",
    "                # Find all TI entries in the reference\n",
    "                ti_matches = re.findall(r'^TI\\s+-\\s+(.+)$', ref, re.MULTILINE)\n",
    "                titles.extend(ti_matches)\n",
    "        return titles\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "def compare_ris_files(file1_path: str, file2_path: str, reference_title: str) -> Set[str]:\n",
    "    \"\"\"Compare two RIS files and find titles in file1 that match reference_title but are absent in file2.\"\"\"\n",
    "    titles1 = parse_ris_file(file1_path)\n",
    "    titles2 = parse_ris_file(file2_path)\n",
    "    \n",
    "    # Find titles in file1 that match the reference title and are not in file2\n",
    "    different_titles = set(t for t in titles1 if t.strip() == reference_title.strip() and t not in titles2)\n",
    "    return different_titles\n",
    "\n",
    "def select_file() -> str:\n",
    "    \"\"\"Open file dialog to select an RIS file.\"\"\"\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"RIS files\", \"*.ris\"), (\"All files\", \"*.*\")])\n",
    "    return file_path\n",
    "\n",
    "def main():\n",
    "    # Initialize Tkinter root\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main window\n",
    "\n",
    "    # Select first RIS file\n",
    "    messagebox.showinfo(\"Select File\", \"Please select the first RIS file.\")\n",
    "    file1_path = select_file()\n",
    "    if not file1_path:\n",
    "        messagebox.showerror(\"Error\", \"No file selected for the first RIS file.\")\n",
    "        return\n",
    "\n",
    "    # Select second RIS file\n",
    "    messagebox.showinfo(\"Select File\", \"Please select the second RIS file.\")\n",
    "    file2_path = select_file()\n",
    "    if not file2_path:\n",
    "        messagebox.showerror(\"Error\", \"No file selected for the second RIS file.\")\n",
    "        return\n",
    "\n",
    "    # Reference title to compare\n",
    "    reference_title = \"3D Human Pose Estimation with Dilated Sampled Frames\"\n",
    "\n",
    "    # Compare the files\n",
    "    different_titles = compare_ris_files(file1_path, file2_path, reference_title)\n",
    "\n",
    "    # Display results\n",
    "    if different_titles:\n",
    "        result = f\"The following title was found in {os.path.basename(file1_path)} but not in {os.path.basename(file2_path)}:\\n\"\n",
    "        result += \"\\n\".join(different_titles)\n",
    "    else:\n",
    "        result = f\"The title '{reference_title}' was either not found in {os.path.basename(file1_path)} or present in both files.\"\n",
    "\n",
    "    messagebox.showinfo(\"Comparison Result\", result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
